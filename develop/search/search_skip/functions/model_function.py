#å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
#å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

import numpy as np
import pandas as pd
import random
import tensorflow as tf
from tensorflow import keras

from tensorflow.keras import layers, losses, initializers
from tensorflow.keras.callbacks import EarlyStopping

import os
import sys


from custom_Class.custom_earlystopping import CustomAutoencoder
from custom_Class.custom_earlystopping import MaxReconstructionErrorEarlyStopping

from keras.saving import register_keras_serializable

import multiprocessing
from functools import partial
import logging
import config



# ã‚·ãƒ¼ãƒ‰å€¤ã‚’æ±ºå®šã™ã‚‹é–¢æ•°
def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)

#ãƒ‡ãƒ¼ã‚¿ã®å†æ§‹æˆå€¤ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
@register_keras_serializable()
def root_mean_squared_error(y_true, y_pred):
    mse_total = tf.reduce_mean(tf.square(y_pred - y_true))  # ã‚¹ã‚«ãƒ©ãƒ¼
    rmse_total = tf.sqrt(mse_total)  # ã‚¹ã‚«ãƒ©ãƒ¼ â†’ RMSE_total)
    return rmse_total

#å„ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦å†æ§‹æˆå€¤ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
def root_mean_squared_error_per_data(y_true, y_pred):
    mse_per_sample = tf.reduce_mean(tf.square(y_pred - y_true), axis=1)
    rmse_per_sample = tf.sqrt(mse_per_sample)
    #ãƒ‡ãƒ¼ã‚¿è¡Œï¼‘åˆ—ã«å¤‰æ›
    errors = tf.reshape(rmse_per_sample,(-1,1))
    return errors


#å„ç‰¹å¾´é‡ã”ã¨ã®å†æ§‹æˆèª¤å·®ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
def calcurate_reconstraction_error_per_features(y_true, y_pred):
    #å·®ã‚’å–ã£ã¦äºŒä¹—ã™ã‚‹è¨ˆç®—
    reconstraction_errors = np.sqrt((y_true - y_pred) ** 2)

    #å„ç‰¹å¾´é‡ã”ã¨ã«å¹³å‡ã‚’ã¨ã‚‹ 
    mean_errors_per_feature = np.mean(reconstraction_errors,axis=0)
    
    return mean_errors_per_feature



def calcurate_data(train_data, test_data, train_predict_data, test_predict_data, flag_skip=0):
    #åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã®è¨ˆç®—
    errors_train = root_mean_squared_error_per_data(train_data, train_predict_data)
    errors_predict = root_mean_squared_error_per_data(test_data, test_predict_data)

    #ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹å†æ§‹æˆèª¤å·®ã®è¨ˆç®—
    reconstract_error = root_mean_squared_error(train_data, train_predict_data)

    #å„ãƒ‡ãƒ¼ã‚¿ã”ã¨ã®å†æ§‹æˆèª¤å·®
    errors_train_per_data = errors_train

    errors_train_per_features = calcurate_reconstraction_error_per_features(train_data,train_predict_data)
    errors_train_per_features = pd.DataFrame([errors_train_per_features], columns=config.columns_list)

    errors_predict_per_features = calcurate_reconstraction_error_per_features(test_data,test_predict_data)
    errors_predict_per_features = pd.DataFrame([errors_predict_per_features], columns=config.columns_list)

    #å„ç‰¹å¾´é‡ã€å„ãƒ‡ãƒ¼ã‚¿ã®train_dataã®å†æ§‹æˆèª¤å·®
    errors_per_data_per_features = np.sqrt((train_data - train_predict_data) ** 2)
    errors_per_data_per_features = pd.DataFrame(errors_per_data_per_features,columns=config.columns_list)

    #ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç•°å¸¸åº¦ã®è¨ˆç®—
    abnormal_score = errors_predict
    #ä¸€æ¬¡å…ƒé…åˆ—ã«å¤‰æ›´
    abnormal_score = abnormal_score.numpy().flatten()

    #é–¾å€¤ã®è¨ˆç®—
    thresold = errors_train.numpy().max()

    #ç‰¹å¾´é‡ã”ã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹å†æ§‹æˆèª¤å·®ã®å¹³å‡
    errors_train_per_features = pd.DataFrame(errors_train_per_features, columns= config.columns_list)
    errors_train_per_features_ave = errors_train_per_features[config.columns_list].mean()

    #ç‰¹å¾´é‡ã”ã¨ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹å†æ§‹æˆèª¤å·®ã®å¹³å‡
    errors_predict_per_features = pd.DataFrame(errors_predict_per_features, columns=config.columns_list)
    errors_predict_per_features_ave = errors_predict_per_features[config.columns_list].mean()

    #é–¾å€¤ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡ã”ã¨ã®å†æ§‹æˆèª¤å·®
    max_position = int(tf.argmax(errors_train).numpy())
    print(f"æœ€ã‚‚å†æ§‹æˆèª¤å·®ãŒå¤§ãã‹ã£ãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç•ªå·ï¼š{max_position}")
    thresold_per_features = errors_per_data_per_features.iloc[max_position]

    

    if flag_skip == 0:
        return abnormal_score, thresold, errors_train_per_features_ave, errors_predict_per_features_ave, thresold_per_features, reconstract_error, errors_train_per_data
    
    else:
        return abnormal_score, errors_predict_per_features_ave






#AutoEncoderã®ãƒ¢ãƒ‡ãƒ«
def model_autoencoder(params, init_num, unit13, unit2):
    #ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å–å¾—

    learning_rate = params["learning_rate"]
    # ã‚·ãƒ¼ãƒ‰å€¤ã®æŠœãå‡ºã—
    seeds = params["seeds"]

    #ï¼’ï¼Œã‚·ãƒ¼ãƒ‰å€¤ã®ã‚»ãƒƒãƒˆ
    set_seed(seeds[init_num])

    # ãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦
    #ã€€ä¸­é–“å±¤æ•°ã¯ï¼“ã§è¨­å®šã€‚ä¸­é–“å±¤ï¼‘ã¨ï¼“ã¯åŒã˜ãƒ¦ãƒ‹ãƒƒãƒˆæ•°

    # ãƒ¦ãƒ‹ãƒƒãƒˆæ•°ã®å®šç¾©
    input_unit = 11
    middle_unit_1 = unit13
    middle_unit_2 = unit2
    middle_unit_3 = unit13
    output_unit = 11

    # ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã®å®šç¾©ï¼ˆFunctional APIï¼‰
    inputs = keras.Input(shape=(input_unit,))
    x = layers.Dense(units=middle_unit_1, activation="sigmoid",
                     kernel_initializer=initializers.TruncatedNormal(mean=0.0, stddev=pow(unit13, -0.5), seed=seeds[init_num]))(inputs)
    x = layers.Dense(units=middle_unit_2, activation="sigmoid",
                     kernel_initializer=initializers.TruncatedNormal(mean=0.0, stddev=pow(unit2, -0.5), seed=seeds[init_num]))(x)
    x = layers.Dense(units=middle_unit_3, activation="sigmoid",
                     kernel_initializer=initializers.TruncatedNormal(mean=0.0, stddev=pow(unit13, -0.5), seed=seeds[init_num]))(x)
    outputs = layers.Dense(units=output_unit, activation="linear",
                           kernel_initializer=initializers.TruncatedNormal(mean=0.0, stddev=pow(175, -0.5), seed=seeds[init_num]))(x)

    model = CustomAutoencoder(inputs, outputs)
    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)
    model.compile(optimizer=optimizer, loss=root_mean_squared_error)

    return model



# å®Ÿéš›ã«å­¦ç¿’ã‚’è¡Œã†é–¢æ•°
#@tf.function
def learn_model(params, model , train_data, logger):
    #ï¼‘ï¼Œãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã°ã‚‰ã™
    batch_size = params["batch_size"]
    max_epochs = params["max_epochs"]
    early_stopping_params = params["early_stopping_params"]


    # early_stoppingã®è¨­å®š
    early_stopping = MaxReconstructionErrorEarlyStopping(model, early_stopping_params, logger=logger)

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã™
    model.train_data_for_monitoring = train_data

    #å­¦ç¿’é€Ÿåº¦é«˜é€ŸåŒ–ã®ãŸã‚tfå½¢å¼ã«å¤‰æ›´ã™ã‚‹
    # 2. ãƒ‡ãƒ¼ã‚¿å‹ã®çµ±ä¸€
    train_data = tf.cast(train_data, dtype=tf.float32)  # TensorFlowç”¨ã«å‹å¤‰æ›

    history = 0

    #ã€€å­¦ç¿’ã®é–‹å§‹
    history = model.fit(train_data, train_data, epochs = max_epochs, batch_size = batch_size, verbose = 0
                        , shuffle = True, validation_data = (train_data,train_data) ,callbacks=[early_stopping] )
    
    # EarlyStoppingã§æ‰“ã¡åˆ‡ã‚‰ã‚ŒãŸã‹ã©ã†ã‹ã‚’ç¢ºèªã™ã‚‹
    if hasattr(model, 'reached_threshold') and model.reached_threshold:
        logger.info(f"ãƒ¢ãƒ‡ãƒ«ã¯ EarlyStopping ã«ã‚ˆã‚Šé–¾å€¤ã‚’æº€ãŸã—ã¦åœæ­¢ã—ã¾ã—ãŸã€‚ï¼ˆ{len(history.epoch)} ã‚¨ãƒãƒƒã‚¯ï¼‰")
    else:
        logger.info("ãƒ¢ãƒ‡ãƒ«ã¯æœ€å¤§ã‚¨ãƒãƒƒã‚¯æ•°ã¾ã§åæŸæ¡ä»¶ã«é”ã—ã¾ã›ã‚“ã§ã—ãŸã€‚åæŸæ¡ä»¶ã‚’æº€ãŸã•ãšçµ‚äº†ã—ã¾ã—ãŸã€‚")

    
    return model


def initialize_log_files(seeds,period_log):
    for seed in seeds:
        log_filename = f"log_seed_{period_log}_{seed}.log"
        with open(log_filename, mode='w', encoding='utf-8') as f:
            f.write('')  # ç©ºã«ã™ã‚‹


def set_up_logger(log_file):
    logger = logging.getLogger(log_file)
    logger.setLevel(logging.INFO)

    # æ—¢å­˜ã®å…¨ã¦ã® handler ã‚’å‰Šé™¤ï¼ˆé‡è¦ï¼ï¼ï¼‰
    if logger.hasHandlers():
        logger.handlers.clear()

    fh = logging.FileHandler(log_file, mode='a', encoding='utf-8')
    formatter = logging.Formatter('%(asctime)s %(message)s')
    fh.setFormatter(formatter)
    logger.addHandler(fh)

    return logger


#ã€€åˆ†æ•£å‡¦ç†ã®ãŸã‚ã®é–¢æ•°,å„åˆæœŸå€¤ã§ã®å®Ÿè¡Œ
def run_one_seed(params, train_data, unit_1_3, unit_2, period_log, init_num):

    # seedã®å–ã‚Šå‡ºã—
    seed = params["seeds"][init_num]  # ä¾‹ï¼šseeds = [50, 51, 52, 53]
    set_seed(seed)


    log_filename = f"log_seed_{period_log}_{seed}.log"
    logger = set_up_logger(log_filename)

    logger.info("-----------------------------------------------------------------------------------------")
    logger.info(f"æ¢ç´¢ä¸­: units_1_3={unit_1_3}, units_2={unit_2}, è©¦è¡Œå›æ•°={init_num+1}, seedå€¤ = {seed}")

    model = model_autoencoder(params, init_num, unit_1_3, unit_2)
    model = learn_model(params, model, train_data, logger)


    #ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å†æ§‹æˆèª¤å·®ã®è¨ˆç®—
    train_predict = model.predict(train_data, verbose = 0)
    train_errors = root_mean_squared_error(train_data, train_predict)
    train_errors_max = root_mean_squared_error_per_data(train_data, train_predict).numpy().max()

    logger.info(f"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å†æ§‹æˆèª¤å·®ï¼ˆå¹³å‡ï¼‰ï¼š{train_errors}")
    logger.info(f"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å†æ§‹æˆèª¤å·®ï¼ˆæœ€å¤§å€¤ï¼‰ï¼š{train_errors_max}")

    if hasattr(model, 'reached_threshold') and model.reached_threshold:
        logger.info(f"é–¾å€¤ã‚’ä¸‹å›ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ç™ºè¦‹: units_1_3={unit_1_3}, units_2={unit_2}")
        return model, True
    else:
        logger.info("é–¾å€¤ã‚’ä¸‹å›ã‚Šã¾ã›ã‚“ã§ã—ãŸ"+ str(init_num+1) +"å›ç›®")  
        return model, False




#ã€€åˆæœŸå€¤ã®å‰²ã‚ŠæŒ¯ã‚Šã‚’è¡Œã†é–¢æ•°
def try_init_point(params, train_data, unit_1_3, unit_2, period_log):
    #åˆæœŸå€¤ã®å‰²ã‚ŠæŒ¯ã‚Š

    #ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å–å¾—
    num_retry = params["num_retry"]

    print(f"å­¦ç¿’æœŸé–“: {period_log}")
    
    # ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ã§ã®å®Ÿè¡Œ
    with multiprocessing.Pool(processes=num_retry) as pool:
        result_iter = pool.imap_unordered(
        partial(run_one_seed, params, train_data, unit_1_3, unit_2, period_log),
        list(range(num_retry)) 
    )
        success_found = False

        for model, success in result_iter:
            if success:
                print("âœ… æœ‰åŠ¹ãªãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã£ãŸã®ã§ä¸¦åˆ—å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™")
                success_found = True
                break
            else:
                print("é–¾å€¤ã‚’ä¸‹å›ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        # å…¨éƒ¨å¤±æ•—
        pool.close()
        pool.join()

        if success_found:
            return model, True

        else:
            print(f"å…¨ã¦ã®åˆæœŸå€¤ã§é–¾å€¤ã‚’ä¸‹å›ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ (units_1_3={unit_1_3}, units_2={unit_2})")
            print("----------------------------------------------------------------------------------------------------------------")
            return model, False



#æ¬¡ã®ãƒãƒ¼ãƒ‰æ•°ã‚’å†å¸°çš„ã«æ¢ç´¢ã™ã‚‹é–¢æ•°
def search_unit13_recursive(params, train_data, unit2, period_log ,lower_bound, upper_bound, best_model=None, best_unit13=None, min_total_units=float('inf')):
    """
    unit13ã‚’å†å¸°çš„ã«æ¢ç´¢ã™ã‚‹é–¢æ•°ã€‚
    lower_bound: é–¾å€¤ã‚’ä¸Šå›ã£ãŸunit13ï¼ˆéé©åˆï¼‰
    upper_bound: é–¾å€¤ã‚’ä¸‹å›ã£ãŸunit13ï¼ˆé©åˆï¼‰
    """
    # æ‰“ã¡åˆ‡ã‚Šæ¡ä»¶
    if upper_bound - lower_bound <= 1:
        return best_model, best_unit13, min_total_units

    mid_unit13 = (lower_bound + upper_bound) // 2


    print("----------------------------------------------------------------------------------------------------------------")
    print(f"[å†å¸°æ¢ç´¢] unit13={mid_unit13}, unit2={unit2}")
    model, flag_low_threshold = try_init_point(params, train_data, mid_unit13, unit2, period_log)
    total_units = mid_unit13 * 2 + unit2

    if flag_low_threshold:
        print(f"âœ… é–¾å€¤ã‚’ä¸‹å›ã‚Šã¾ã—ãŸ: unit13={mid_unit13}")
        if total_units < min_total_units:
            best_model = model
            best_unit13 = mid_unit13
            min_total_units = total_units

        # å†å¸°çš„ã«ä¸‹é™ã‚’æ›´æ–°    
        return search_unit13_recursive(params, train_data, unit2, period_log,lower_bound, mid_unit13, best_model, best_unit13, min_total_units)
    else:
        # å†å¸°çš„ã«ä¸Šé™ã‚’æ›´æ–°
        return search_unit13_recursive(params, train_data, unit2, period_log,mid_unit13, upper_bound, best_model, best_unit13, min_total_units)


            
# ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ¼ãƒ‰æ•°ã‚’æ¢ç´¢ã™ã‚‹é–¢æ•°
def search_optimal_units(params, train_data, period_log):
    # åˆæœŸå€¤ã®è¨­å®š
    best_model = None
    best_unit_1_3 = None
    best_unit_2 = None
    min_total_units = float("inf")

    #ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å–å¾—
    units = params["unit"]
    first_unit13 = units * 2
    max_unit2 = units - 1

    # ãƒ¦ãƒ‹ãƒƒãƒˆæ•°ã‚’ä¿æŒã™ã‚‹å¤‰æ•°
    previous_best_unit13 = None  # unit2=10ã®ã¨ãã®æœ€è‰¯unit13
    previous_unit2 = None

    #çµ‚ã‚ã‚Šã®ãƒ•ãƒ©ã‚°
    end_flag = False



    #æ¢ç´¢é–‹å§‹
    for unit_2 in reversed(range(1,max_unit2+1)):
        print(f"\n===== unit2={unit_2} ã®æ¢ç´¢é–‹å§‹ =====")
        #unit_2ã«å¯¾å¿œã™ã‚‹æœ€é©ãƒ¦ãƒ‹ãƒƒãƒˆæ•°ã€ã¹ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã€å†æ§‹æˆèª¤å·®ã‚’è¨˜éŒ²ã™ã‚‹å¤‰æ•°ã‚’ä½œæˆ

        if previous_best_unit13 is None:
            unit13 = first_unit13
        else:
            # å°‘æ•°åˆ‡ã‚Šæ¨ã¦
            unit13 = (previous_best_unit13 * 2 + previous_unit2 - unit_2) // 2
        print(f"unit2={unit_2} ã«å¯¾ã™ã‚‹unit13æ¢ç´¢é–‹å§‹ç‚¹: {unit13}")

        # æ¢ç´¢ã—ãŸãƒ¦ãƒ‹ãƒƒãƒˆæ•°ã‚’è¨˜éŒ²ã™ã‚‹ã‚»ãƒƒãƒˆ
        searched_unit13 = set()

        #ãƒãƒ¼ãƒ‰æ¢ç´¢ã«ä½¿ç”¨ã™ã‚‹å¤‰æ•°
        lower = units+1
        upper = None


        # å„unit13ã«å¯¾ã™ã‚‹upperã‚’å®šç¾©ã™ã‚‹
        if unit_2 == max_unit2:
            unit13 = first_unit13
            while True:
                print("----------------------------------------------------------------------")
                print(f"[unit10æ¢ç´¢] unit13={unit13}, unit2={unit_2}")

                searched_unit13.add(unit13)

                # ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
                model, flag_low_threshold = try_init_point(params, train_data, unit13, unit_2, period_log)

                if flag_low_threshold:
                    #upperã®ä»£å…¥
                    upper = unit13
                    total_units = unit13 * 2 + unit_2
                    min_total_units = total_units
                    best_model = model
                    best_unit_1_3 = unit13
                    best_unit_2 = unit_2
                    print(f"ğŸ‰ æœ€è‰¯ãƒ¢ãƒ‡ãƒ«æ›´æ–°: unit13={unit13}, unit2={unit_2}, åˆè¨ˆ={total_units}")
                    unit13 = (upper + lower) // 2  # åˆæœŸå€¤ã‚’è¨­å®š
                    break
                
                lower = unit13
                unit13 *= 2  # è¦‹ã¤ã‹ã‚‹ã¾ã§å€ã€…æ¢ç´¢
                

        else:
            # unit2 < 10 ã®ã¨ãï¼šupper ã¯éå»ã®ãƒ™ã‚¹ãƒˆæ§‹æˆã‹ã‚‰è¨ˆç®—
            upper = ((best_unit_1_3 * 2 + best_unit_2) - unit_2 ) // 2
            unit13 = upper # åˆæœŸå€¤ã‚’è¨­å®š


        # unit13ã®æ¢ç´¢
        while True:
            # åæŸã™ã‚‹ã‹ã€å…¥åŠ›ãƒãƒ¼ãƒ‰æ•°ã‚’ä¸‹å›ã£ãŸã‚‰çµ‚äº†
            if unit13 in searched_unit13 or unit13 <= units:
                
                print(f"æ¢ç´¢ãŒåæŸ or ç¯„å›²å¤–ï¼ˆunit13={unit13}ï¼‰ã€‚unit2={unit_2} ã®æ¢ç´¢çµ‚äº†ã€‚")
                break

            searched_unit13.add(unit13)
            print(f"[æ¢ç´¢ã®é–‹å§‹] unit13={unit13}, unit2={unit_2}")

            #ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
            model, flag_low_threshold = try_init_point(params, train_data, unit13, unit_2, period_log)

            if flag_low_threshold == False and len(searched_unit13) == 1 and unit_2 != max_unit2:
                # åˆå›ã®æ¢ç´¢ã§é–¾å€¤ã‚’ä¸‹å›ã‚‰ãªã‹ã£ãŸå ´åˆã€æ¢ç´¢ã‚’çµ‚äº†
                print(f"unit2={unit_2} ã«å¯¾ã™ã‚‹unit13={unit13} ã§ã‚‚é–¾å€¤ã‚’ä¸‹å›ã‚‰ãªã‹ã£ãŸã®ã§ä»¥é™ã®æ¢ç´¢ã‚’å®Œå…¨ã«çµ‚äº†ã—ã¾ã™")
                
                if best_model is None:
                    print("â— æœ€é©ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æœ€å¾Œã«æ¢ç´¢ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’è¿”ã—ã¾ã™ã€‚")
                    return model
                
                end_flag = True
                break

            #é–¾å€¤ã‚’ä¸‹å›ã£ãŸå ´åˆã€æœ€é©ãªãƒ¦ãƒ‹ãƒƒãƒˆæ•°ã‚’æ›´æ–°
            if flag_low_threshold == True:
                total_units = unit13 * 2 + unit_2
                if total_units < min_total_units:
                    min_total_units = total_units
                    best_model = model
                    best_unit_1_3 = unit13
                    best_unit_2 = unit_2
                    print(f"ğŸ‰ æœ€è‰¯ãƒ¢ãƒ‡ãƒ«æ›´æ–°: unit13={unit13}, unit2={unit_2}, åˆè¨ˆ={total_units}")
                    print("------------------------------------------------------------------------------------------")
                upper = unit13

                # æ¢ç´¢ã®å†å¸°çš„ãªå‘¼ã³å‡ºã—
                model, best_unit1_3, min_total_units = search_unit13_recursive(
                    params, train_data, unit_2, period_log,lower, upper, best_model, unit13, min_total_units
                )
                best_model = model
                best_unit_1_3 = best_unit1_3
                best_unit_2 = unit_2
                print("===========================================================================")
                print(f"âœ… unit2={unit_2} ã«å¯¾ã—ã¦æ±ºå®šã•ã‚ŒãŸ unit13={best_unit1_3}")
                break
                
            else:
                lower = unit13
            

                model, best_unit1_3, min_total_units = search_unit13_recursive(
                    params, train_data, unit_2, period_log ,lower, upper, best_model, upper, min_total_units
                )
                best_model = model
                best_unit_1_3 = best_unit1_3
                best_unit_2 = unit_2
                print("===========================================================================")
                print(f"âœ… unit2={unit_2} ã«å¯¾ã—ã¦æ±ºå®šã•ã‚ŒãŸ unit13={best_unit1_3}")
                break
                

        # unit2ã§ã®æ¢ç´¢ãŒçµ‚äº†ã—ãŸå ´åˆã€æœ€é©ãªãƒ¦ãƒ‹ãƒƒãƒˆæ•°ã‚’è¨˜éŒ²
        previous_best_unit13 = best_unit_1_3
        previous_unit2 = best_unit_2

        if end_flag:
            # æ¢ç´¢ã‚’çµ‚äº†ã™ã‚‹ãƒ•ãƒ©ã‚°ãŒç«‹ã£ãŸå ´åˆã€ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
            print("æ¢ç´¢ã‚’çµ‚äº†ã—ã¾ã™")
            break


    if best_model is None:
        print("â— æœ€é©ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æœ€å¾Œã«æ¢ç´¢ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’è¿”ã—ã¾ã™ã€‚")
        return model
    
    # æœ€é©ãªãƒ¦ãƒ‹ãƒƒãƒˆæ•°ã‚’è¨˜éŒ²
    print("\n===== æœ€é©æ§‹æˆã®å‡ºåŠ› =====")
    print(f"æœ€é©ãƒãƒ¼ãƒ‰æ•°: unit13={best_unit_1_3}, unit2={best_unit_2}")
    print(f"åˆè¨ˆãƒãƒ¼ãƒ‰æ•°: {min_total_units}")
    return best_model

        